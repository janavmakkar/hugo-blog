{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3765df74-627c-4427-a722-f73c6d63780c",
   "metadata": {},
   "source": [
    "## 1. Random Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0083d43-2d39-46f6-8c86-3105f309799b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "201bf109-b11c-4875-9fb9-74e9cf6555f6",
   "metadata": {},
   "source": [
    "## 2. Decorators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65f1356-79da-415c-9bec-691c7ae21f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c9c7574-3ed1-4d09-ad4d-6c419f33fa2e",
   "metadata": {},
   "source": [
    "## 3. Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d34d14-51c8-4fa5-97c8-8901f5f74413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81b1497f-06ec-4e07-b6bd-99c1e45338e3",
   "metadata": {},
   "source": [
    "## 4. Threading vs Multiprocessing (Theory time ðŸ¤“)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1de13c4-1b50-4796-9bb8-dc96537f09a1",
   "metadata": {},
   "source": [
    "\n",
    "## Process:\n",
    "- An instance of program\n",
    "- Takes advantage of multiple CPU's & cores\n",
    "- Memory is not shared b/w processes\n",
    "- Great for cpu-bound processing\n",
    "- New process is started independently of another process\n",
    "- they are killable/interruptable\n",
    "- One GIL (Global interpreter lock) for each process -> avoid GIL limitation\n",
    "- More resource-intensive as each process\n",
    "- Higher overhead due to inter-process communication\n",
    "- Better for CPU-intensive tasks (like complex calculations)\n",
    "- Starting a process is slower that starting a thread\n",
    "- Larger memory footprint\n",
    "\n",
    "\n",
    "## Threads:\n",
    "An entity within a process that can be scheduled for execution (Also known as \"leightweight process\"). A Process can spawn multiple threads. The main difference is that all threads within a process share the same memory.\n",
    "\n",
    "- Multiple threads can be spawned within one process\n",
    "- Memory is shared between all threads\n",
    "- Starting a thread is faster than starting a process\n",
    "- Great for I/O-bound tasks\n",
    "- Leightweight - low memory footprint\n",
    "- One GIL for all threads, i.e. threads are limited by GIL\n",
    "- Multithreading has no effect for CPU-bound tasks due to the GIL\n",
    "- Not interruptible/killable -> be careful with memory leaks\n",
    "- increased potential for race conditions\n",
    "\n",
    "## GIL - Global interpreter lock\n",
    "- Lock that allows only one thread to hold control of the Python interpreter. \n",
    "- It allows only one thread to execute at a time even in a multi-threaded architecture.\n",
    "\n",
    "### Why is it needed?\n",
    "It is needed because CPython's (reference implementation of Python) memory management is not thread-safe. \n",
    "Python uses reference counting for memory management.\n",
    "\n",
    "It means that objects created in Python have a reference count variable that keeps track of the number of references that point to the object. \n",
    "When this count reaches zero, the memory occupied by the object is released. \n",
    "The problem was that this reference count variable needed protection from race conditions where two threads increase or decrease its value simultaneously. \n",
    "\n",
    "If this happens, it can cause either leaked memory that is never released or incorrectly release the memory while a reference to that object still exists.\n",
    "\n",
    "### How to avoid the GIL\n",
    "The GIL is very controversial in the Python community. \n",
    "The main way to avoid the GIL is by using multiprocessing instead of threading. \n",
    "Another (however uncomfortable) solution would be to avoid the CPython implementation and use a free-threaded Python implementation like Jython or IronPython. \n",
    "A third option is to move parts of the application out into binary extensions modules, i.e. use Python as a wrapper for third party libraries (e.g. in C/C++). This is the path taken by numypy and scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89a7edf1-1d21-4fa8-8b13-a7252fb248cd",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End main process\n",
      "End main thread\n"
     ]
    }
   ],
   "source": [
    "# Multiprocessing\n",
    "from multiprocessing import Process\n",
    "import os \n",
    "import time\n",
    "\n",
    "def sqaure():\n",
    "    for i in range(100):\n",
    "        i*i\n",
    "        time.sleep(0.01)\n",
    "\n",
    "processes=[]\n",
    "num_process = os.cpu_count()\n",
    "\n",
    "for i in range(num_process):\n",
    "    p = Process(target=sqaure)\n",
    "    processes.append(p)\n",
    "\n",
    "for p in processes:\n",
    "    p.start()\n",
    "\n",
    "# join is used to block main thread until all processes are finished \n",
    "for p in processes:\n",
    "    p.join()\n",
    "    \n",
    "print('End main process')\n",
    "\n",
    "# -----------------------\n",
    "\n",
    "# Multithreading\n",
    "from threading import Thread\n",
    "        \n",
    "threads=[]\n",
    "num_threads = 11\n",
    "\n",
    "for i in range(num_threads):\n",
    "    t = Thread(target=sqaure)\n",
    "    threads.append(t)\n",
    "\n",
    "for t in threads:\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "    \n",
    "print('End main thread')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2198b176-ddb3-4c7c-9225-cf00c2debfaf",
   "metadata": {},
   "source": [
    "## 5. Multithreading\n",
    "\n",
    "- Locks are used to avoid race condition \n",
    "- A lock is like a token that only one thread can hold at a time. \n",
    "- Other threads must wait until the lock is released.\n",
    "- A race condition occurs when two or more threads can access shared data and they try to change it at the same time.\n",
    "- Because the thread scheduling algorithm can swap between threads at any time, you don't know the order in which the threads will attempt to access the shared data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a604acbf-47cf-4218-b73f-28765580bf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start db_val:  0\n",
      "End db_val:  1\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "db_val=0\n",
    "\n",
    "def increase():\n",
    "    global db_val\n",
    "    local_val=db_val\n",
    "    local_val+=1\n",
    "    time.sleep(0.01)\n",
    "    db_val=local_val\n",
    "    # time.sleep(0.01)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    print('Start db_val: ', db_val)\n",
    "    \n",
    "    t1 = Thread(target=increase)\n",
    "    t2 = Thread(target=increase)\n",
    "\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "    \n",
    "    print('End db_val: ', db_val) \n",
    "    # due to race condition caused by t1's sleep time execution of thread\n",
    "    # shifts to t2 being executed in meantime and both threads end up copying 1 into db_val\n",
    "    # this can be avoided by using locks\n",
    "    # so we get 1 instead of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e11b0f7e-a696-48c5-bcb9-56217aa8f031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start db_val:  0\n",
      "End db_val:  2\n"
     ]
    }
   ],
   "source": [
    "# Locks are used to avoid race condition \n",
    "# A lock is like a token that only one thread can hold at a time. \n",
    "# If a thread wants to access shared resources, it must first acquire the lock. \n",
    "# Other threads must wait until the lock is released.\n",
    "# If the state is locked, it does not allow other concurrent threads to enter this code section until the state is unlocked again.\n",
    "\n",
    "from threading import Thread, Lock\n",
    "import time\n",
    "\n",
    "db_val=0\n",
    "\n",
    "def increase(lock):\n",
    "    global db_val\n",
    "\n",
    "    lock.acquire()\n",
    "    local_val=db_val\n",
    "\n",
    "    # processing\n",
    "    local_val+=1\n",
    "    time.sleep(0.01)\n",
    "    db_val=local_val\n",
    "    \n",
    "    lock.release()\n",
    "\n",
    "\n",
    "# using lock with context manager \n",
    "def increase2(lock):\n",
    "    global db_val\n",
    "\n",
    "    with lock:\n",
    "        local_val=db_val\n",
    "        local_val+=1\n",
    "        time.sleep(0.01)\n",
    "        db_val=local_val\n",
    "\n",
    "if __name__=='__main__':\n",
    "    print('Start db_val: ', db_val)\n",
    "    lock = Lock()\n",
    "    t1 = Thread(target=increase2, args=(lock,))\n",
    "    t2 = Thread(target=increase2, args=(lock,))\n",
    "\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "    \n",
    "    print('End db_val: ', db_val) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83da947-a22d-469d-b793-3e3dc2fa18e7",
   "metadata": {},
   "source": [
    "## 5.1 Queues for mt-mp data exchange\n",
    "\n",
    "Queues can be used for thread-safe/process-safe data exchanges and data processing both in a multithreaded and a multiprocessing environment.\n",
    "\n",
    "A queue is a linear data structure that follows the First In First Out (FIFO) principle. A good example is a queue of customers that are waiting in line, where the customer that came first is served first.\n",
    "\n",
    "#### Operations with a queue are thread-safe. Important methods are:\n",
    "\n",
    "- `q.get()` : Remove and return the first item. By default, it blocks until the item is available.\n",
    "- `q.put(item)` : Puts element at the end of the queue. By default, it blocks until a free slot is available.\n",
    "- `q.task_done()` : Indicate that a formerly enqueued task is complete. For each get() you should call this after you are done with your task for this item.\n",
    "- `q.join()` : Blocks until all items in the queue have been gotten and proccessed (task_done() has been called for each item).\n",
    "- `q.empty()` : Return True if the queue is empty.\n",
    "\n",
    "#### Daemon threads\n",
    "- Daemon threads are background threads that automatically die when the main program ends. \n",
    "- This is why the infinite loops inside the worker methods can be exited. Without a daemon process we would have to use a signalling mechanism such as a threading.\n",
    "- Event to stop the worker. But be careful with daemon processes: They are abruptly stopped and their resources (e.g. open files or database transactions) may not be released/completed properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c31bc0-1754-41ea-9a04-b30cd54f6f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in thread_num_1 got 0\n",
      "in thread_num_4 got 1\n",
      "in thread_num_7 got 2\n",
      "in thread_num_9 got 3\n",
      "in thread_num_10 got 4\n",
      "in thread_num_8 got 5\n",
      "in thread_num_2 got 6\n",
      "in thread_num_5 got 7\n",
      "in thread_num_6 got 8\n",
      "in thread_num_3 got 9\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread, Lock, current_thread\n",
    "from queue import Queue\n",
    "\n",
    "def worker(q, lock):\n",
    "    val = q.get() # blocks until the item is available\n",
    "\n",
    "    # do stuff...\n",
    "    with lock: # prevent printing at the same time with this lock\n",
    "        print(f\"in {current_thread().name} got {val}\")\n",
    "        q.task_done()\n",
    "        \n",
    "    # For each get(), a subsequent call to task_done() tells the queue\n",
    "    # that the processing on this item is complete.\n",
    "    # If all tasks are done, q.join() can unblock\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    q = Queue()\n",
    "    lock = Lock()\n",
    "    num_thread = 10\n",
    "\n",
    "    for i in range(num_thread):\n",
    "        t = Thread(name=f\"thread_num_{i+1}\", target=worker, args=(q,lock))\n",
    "        t.daemon = True # dies when the main thread dies\n",
    "        t.start()\n",
    "\n",
    "    # fill the queue with items\n",
    "    for i in range(20):\n",
    "        q.put(i)\n",
    "        \n",
    "    q.join()  # Blocks until all items in the queue have been gotten and processed.\n",
    "    print('main done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c965baa9-d57e-4085-9e79-493e00b24a8b",
   "metadata": {},
   "source": [
    "## 6. Multiprocessing\n",
    "- Call ```process.join()``` to tell the program that it should wait for this process to complete before it continues with the rest of the code.\n",
    "\n",
    "### Share data between processes\n",
    "Since processes don't live in the same memory space, they do not have access to the same (public) data. Thus, they need special shared memory objects to share data.\n",
    "\n",
    "Data can be stored in a shared memory variable using Value or Array.\n",
    "\n",
    "- `Value(type, value)`: Create a ctypes object of type type. Access the value with .target.\n",
    "- `Array(type, value)`: Create a ctypes array with elements of type type. Access the values with [].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4a2915b-1eab-49bc-aaff-7b256e5d4cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value at beginning: 0\n",
      "Array at beginning: [0.0, 100.0, 200.0]\n",
      "Value at end: 0\n",
      "Array at end: [0.0, 100.0, 200.0]\n",
      "end main\n"
     ]
    }
   ],
   "source": [
    "# Task: Create two processes, each process should have access to a shared variable \n",
    "# and modify it (in this case only increase it repeatedly by 1 for 100 times). \n",
    "# Create another two processes that share an array and modify (increase) all the elements in the array.\n",
    "\n",
    "from multiprocessing import Process, Value, Array\n",
    "import time\n",
    "\n",
    "def add_100(num):\n",
    "    for _ in range(100):\n",
    "        time.sleep(0.01)\n",
    "        num.value += 1\n",
    "    \n",
    "def add_100_to_array(nums):\n",
    "    for _ in range(100):\n",
    "        time.sleep(0.01)\n",
    "        for i in range(len(nums)):\n",
    "            nums[i]+=1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    shared_number_1 = Value('i', 0) \n",
    "    print('Value at beginning:', shared_number_1.value)\n",
    "\n",
    "    shared_array = Array('d', [0.0, 100.0, 200.0])\n",
    "    print('Array at beginning:', shared_array[:])\n",
    "\n",
    "    process1 = Process(target=add_100, args=(shared_number_1,))\n",
    "    process2 = Process(target=add_100, args=(shared_number_1,))\n",
    "\n",
    "    process3 = Process(target=add_100_to_array, args=(shared_array,))\n",
    "    process4 = Process(target=add_100_to_array, args=(shared_array,))\n",
    "\n",
    "    process1.start()\n",
    "    process2.start()\n",
    "    process3.start()\n",
    "    process4.start()\n",
    "\n",
    "    process1.join()\n",
    "    process2.join()\n",
    "    process3.join()\n",
    "    process4.join()\n",
    "\n",
    "    print('Value at end:', shared_number_1.value)\n",
    "    print('Array at end:', shared_array[:])\n",
    "\n",
    "    print('end main')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47308c6a",
   "metadata": {},
   "source": [
    "### Race condition\n",
    "A race condition happened here. A race condition occurs when two or more processes or threads can access shared data and they try to change it at the same time. Both processes write the same increased value back into the shared object, and the value was not increased by 2. \n",
    "\n",
    "#### Avoid race conditions with Locks\n",
    "A lock (also known as mutex) is a synchronization mechanism for enforcing limits on access to a resource in an environment where there are many processes/threads of execution. A Lock has two states: locked and unlocked. If the state is locked, it does not allow other concurrent processes/threads to enter this code section until the state is unlocked again.\n",
    "\n",
    "Two functions are important:\n",
    "\n",
    "- `lock.acquire()` : This will lock the state and block\n",
    "- `lock.release()` : This will unlock the state again.\n",
    "Important: You should always release the block again after it was acquired!\n",
    "\n",
    "In obove example the critical code section where the shared variable is read and increased is now locked. This prevents the second process from modyfing the shared object at the same time. \n",
    "\n",
    "### Use the lock as a context manager\n",
    "After lock.acquire() you should never forget to call lock.release() to unblock the code. You can also use a lock as a context manager, wich will safely lock and unlock your code. It is recommended to use a lock this way:\n",
    "\n",
    "```\n",
    "def add_100(number, lock):\n",
    "    for _ in range(100):\n",
    "        time.sleep(0.01)\n",
    "        with lock:\n",
    "            number.value += 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aed6536f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value at beginning: 0\n",
      "Array at beginning: [0.0, 100.0, 200.0]\n",
      "Value at end: 0\n",
      "Array at end: [0.0, 100.0, 200.0]\n",
      "end main\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Lock\n",
    "from multiprocessing import Process, Value, Array\n",
    "import time\n",
    "\n",
    "\n",
    "def add_100(number, lock):\n",
    "    for _ in range(100):\n",
    "        time.sleep(0.01)\n",
    "        # lock the state\n",
    "        lock.acquire()\n",
    "\n",
    "        number.value += 1\n",
    "\n",
    "        # unlock the state\n",
    "        lock.release()\n",
    "\n",
    "\n",
    "def add_100_array(numbers, lock):\n",
    "    for _ in range(100):\n",
    "        time.sleep(0.01)\n",
    "        for i in range(len(numbers)):\n",
    "            lock.acquire()\n",
    "            numbers[i] += 1\n",
    "            lock.release()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # create a lock\n",
    "    lock = Lock()\n",
    "\n",
    "    shared_number = Value(\"i\", 0)\n",
    "    print(\"Value at beginning:\", shared_number.value)\n",
    "\n",
    "    shared_array = Array(\"d\", [0.0, 100.0, 200.0])\n",
    "    print(\"Array at beginning:\", shared_array[:])\n",
    "\n",
    "    # pass the lock to the target function\n",
    "    process1 = Process(target=add_100, args=(shared_number, lock))\n",
    "    process2 = Process(target=add_100, args=(shared_number, lock))\n",
    "\n",
    "    process3 = Process(target=add_100_array, args=(shared_array, lock))\n",
    "    process4 = Process(target=add_100_array, args=(shared_array, lock))\n",
    "\n",
    "    process1.start()\n",
    "    process2.start()\n",
    "    process3.start()\n",
    "    process4.start()\n",
    "\n",
    "    process1.join()\n",
    "    process2.join()\n",
    "    process3.join()\n",
    "    process4.join()\n",
    "\n",
    "    print(\"Value at end:\", shared_number.value)\n",
    "    print(\"Array at end:\", shared_array[:])\n",
    "\n",
    "    print(\"end main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e3929e",
   "metadata": {},
   "source": [
    "### Using a queue in multiprocessing\n",
    "Operations with a queue are process-safe. The multiprocessing Queue implements all the methods of queue.Queue except for task_done() and join(). Important methods are:\n",
    "\n",
    "- `q.get()` : Remove and return the first item. By default, it blocks until the item is available.\n",
    "- `q.put(item)` : Puts element at the end of the queue. By default, it blocks until a free slot is available.\n",
    "- `q.empty()` : Return True if the queue is empty.\n",
    "- `q.close()` : Indicate that no more data will be put on this queue by the current process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4c429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "\n",
    "\n",
    "# communicate between processes with the multiprocessing Queue\n",
    "# Queues are thread and process safe\n",
    "def square(numbers, queue):\n",
    "    for i in numbers:\n",
    "        queue.put(i*i)\n",
    "\n",
    "\n",
    "def negative(numbers, queue):\n",
    "    for i in numbers:\n",
    "        queue.put(i * -1)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    nums = range(1, 6)\n",
    "    q = Queue()\n",
    "\n",
    "    p1 = Process(target=square, args=(nums, q))\n",
    "    p2 = Process(target=negative, args=(nums, q))\n",
    "\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "\n",
    "    while q.empty():\n",
    "        print(q.get())\n",
    "\n",
    "    print(\"end of queue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effcc89e",
   "metadata": {},
   "source": [
    "## Process Pools\n",
    "A process pool object controls a pool of worker processes to which jobs can be submitted It supports asynchronous results with timeouts and callbacks and has a parallel map implementation. It can automatically manage the available processors and split data into smaller chunks which can then be processed in parallel by different processes. See https://docs.python.org/3.7/library/multiprocessing.html#multiprocessing.pool for all possible methods. Important methods are:\n",
    "\n",
    "- `map(func, iterable[, chunksize])` : This method chops the iterable into a number of chunks which it submits to the process pool as separate tasks. The (approximate) size of these chunks can be specified by setting chunksize to a positive integer. It blocks until the result is ready.\n",
    "- `close()` : Prevents any more tasks from being submitted to the pool. Once all the tasks have been completed the worker processes will exit.\n",
    "- `join()`: Wait for the worker processes to exit. One must call close() or terminate() before using join().\n",
    "- `apply(func, args)`: Call func with arguments args. It blocks until the result is ready. func is only executed in ONE of the workers of the pool.\n",
    "\n",
    "Note: There are also asynchronous variants `map_async()` and `apply_async()` that will not block. They can execute callbacks when the results are ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a984160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "def cube(number):\n",
    "    return number * number * number\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    numbers = range(10)\n",
    "\n",
    "    p = Pool()\n",
    "\n",
    "    # by default this allocates the maximum number of available\n",
    "    # processors for this task --> os.cpu_count()\n",
    "    result = p.map(cube, numbers)\n",
    "\n",
    "    # or\n",
    "    # result = [p.apply(cube, args=(i,)) for i in numbers]\n",
    "    # result = p.apply(cube, numbers[0]) \n",
    "\n",
    "    p.close()\n",
    "    p.join()\n",
    "\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03099ab1-d4d4-456c-81f1-db9f65406812",
   "metadata": {},
   "source": [
    "## 7. Function Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e11ee27-0f7d-44a3-a554-9ca3e2343926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n",
      "1 2 3\n",
      "1 2 3\n",
      "1 2 3\n",
      "1 2 3 4\n",
      "1 2 3 100\n",
      "-----------------\n",
      "1 2\n",
      "3\n",
      "4\n",
      "5\n",
      "six 6\n",
      "seven 7\n",
      "\n",
      "1 2\n",
      "three 3\n",
      "-----------------\n",
      "1 2 3 4\n",
      "8\n",
      "9\n",
      "10\n",
      "50\n",
      "-----------------\n",
      "4 5 6\n",
      "1 2 3\n"
     ]
    }
   ],
   "source": [
    "def foo1(a, b, c):\n",
    "    print(a, b, c)\n",
    "\n",
    "\n",
    "# positional arguments\n",
    "foo1(1, 2, 3)\n",
    "\n",
    "# keyword arguments\n",
    "foo1(a=1, b=2, c=3)\n",
    "foo1(c=3, b=2, a=1)  # Note that the order is not important here\n",
    "\n",
    "# mix of both\n",
    "foo1(1, b=2, c=3)\n",
    "\n",
    "# This is not allowed:\n",
    "# foo(1, b=2, 3) # positional argument after keyword argument\n",
    "# foo(1, b=2, a=3) # multiple values for argument 'a'\n",
    "\n",
    "\n",
    "# default arguments\n",
    "def foo2(a, b, c, d=4):\n",
    "    print(a, b, c, d)\n",
    "\n",
    "\n",
    "foo2(1, 2, 3, 4)\n",
    "foo2(1, b=2, c=3, d=100)\n",
    "\n",
    "# not allowed: default arguments must be at the end\n",
    "# def foo(a, b=2, c, d=4):\n",
    "#     print(a, b, c, d)\n",
    "\n",
    "print(\"-----------------\")\n",
    "\n",
    "\n",
    "# Variable-length arguments (*args and **kwargs)\n",
    "# If you mark a parameter with one asterisk (*), you can pass any number of positional arguments to your function (Typically called *args)\n",
    "# If you mark a parameter with two asterisks (**), you can pass any number of keyword arguments to this function (Typically called **kwargs).\n",
    "\n",
    "def foo3(a, b, *args, **kwargs):\n",
    "    print(a, b)\n",
    "    for arg in args:\n",
    "        print(arg)\n",
    "    for kwarg in kwargs:\n",
    "        print(kwarg, kwargs[kwarg])\n",
    "\n",
    "# 3, 4, 5 are combined into args\n",
    "# six and seven are combined into kwargs\n",
    "foo3(1, 2, 3, 4, 5, six=6, seven=7)\n",
    "print()\n",
    "\n",
    "# omitting of args or kwargs is also possible\n",
    "foo3(1, 2, three=3)\n",
    "\n",
    "print(\"-----------------\")\n",
    "\n",
    "# Forced keyword arguments\n",
    "# Sometimes you want to have keyword-only arguments. You can enforce that with:\n",
    "\n",
    "# If you write '*,' in your function parameter list, all parameters after that must be passed as keyword arguments.\n",
    "# Arguments after variable-length arguments must be keyword arguments.\n",
    "\n",
    "def foo4(a, b, *, c, d):\n",
    "    print(a, b, c, d)\n",
    "\n",
    "foo4(1, 2, c=3, d=4)\n",
    "# not allowed:\n",
    "# foo(1, 2, 3, 4)\n",
    "\n",
    "# arguments after variable-length arguments must be keyword arguments\n",
    "def foo5(*args, last):\n",
    "    for arg in args:\n",
    "        print(arg)\n",
    "    print(last)\n",
    "\n",
    "foo5(8, 9, 10, last=50)\n",
    "\n",
    "\n",
    "print(\"-----------------\")\n",
    "\n",
    "# Unpacking into agruments\n",
    "# Lists or tuples can be unpacked into arguments with one asterisk (*) if the length of the container matches the number of function parameters.\n",
    "# Dictionaries can be unpacked into arguments with two asterisks (**) the the length and the keys match the function parameters.\n",
    "def foo6(a, b, c):\n",
    "    print(a, b, c)\n",
    "\n",
    "\n",
    "# list/tuple unpacking, length must match\n",
    "my_list = [4, 5, 6] # or tuple\n",
    "foo6(*my_list)\n",
    "\n",
    "# dict unpacking, keys and length must match\n",
    "my_dict = {'a': 1, 'b': 2, 'c': 3}\n",
    "foo6(**my_dict)\n",
    "\n",
    "# my_dict = {'a': 1, 'b': 2, 'd': 3} # not possible since wrong keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c337b79a-78f3-4029-a268-982070e2c01f",
   "metadata": {},
   "source": [
    "## 8. Shallow vs Deep Copying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67634b01-c9af-411a-b515-f5bcdbca8db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bd91a10-87ce-473d-be65-b087578273ad",
   "metadata": {},
   "source": [
    "## 9. Asterisk Operator *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e1b649-d576-4d30-9391-463bb83b1cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a45bc51-aaaa-479e-8296-1b0398840ff4",
   "metadata": {},
   "source": [
    "## 10. Context Managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc78f5b7-ab4d-43ab-906d-9df011b7f99a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
