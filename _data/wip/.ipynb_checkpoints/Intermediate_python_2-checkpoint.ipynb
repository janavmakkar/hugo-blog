{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3765df74-627c-4427-a722-f73c6d63780c",
   "metadata": {},
   "source": [
    "## 1. Random Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0083d43-2d39-46f6-8c86-3105f309799b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "201bf109-b11c-4875-9fb9-74e9cf6555f6",
   "metadata": {},
   "source": [
    "## 2. Decorators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65f1356-79da-415c-9bec-691c7ae21f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c9c7574-3ed1-4d09-ad4d-6c419f33fa2e",
   "metadata": {},
   "source": [
    "## 3. Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d34d14-51c8-4fa5-97c8-8901f5f74413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81b1497f-06ec-4e07-b6bd-99c1e45338e3",
   "metadata": {},
   "source": [
    "## 4. Threading vs Multiprocessing (Theory time ðŸ¤“)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1de13c4-1b50-4796-9bb8-dc96537f09a1",
   "metadata": {},
   "source": [
    "\n",
    "## Process:\n",
    "- An instance of program\n",
    "- Takes advantage of multiple CPU's & cores\n",
    "- Memory is not shared b/w processes\n",
    "- Great for cpu-bound processing\n",
    "- New process is started independently of another process\n",
    "- they are killable/interruptable\n",
    "- One GIL (Global interpreter lock) for each process -> avoid GIL limitation\n",
    "- More resource-intensive as each process\n",
    "- Higher overhead due to inter-process communication\n",
    "- Better for CPU-intensive tasks (like complex calculations)\n",
    "- Starting a process is slower that starting a thread\n",
    "- Larger memory footprint\n",
    "\n",
    "\n",
    "## Threads:\n",
    "An entity within a process that can be scheduled for execution (Also known as \"leightweight process\"). A Process can spawn multiple threads. The main difference is that all threads within a process share the same memory.\n",
    "\n",
    "- Multiple threads can be spawned within one process\n",
    "- Memory is shared between all threads\n",
    "- Starting a thread is faster than starting a process\n",
    "- Great for I/O-bound tasks\n",
    "- Leightweight - low memory footprint\n",
    "- One GIL for all threads, i.e. threads are limited by GIL\n",
    "- Multithreading has no effect for CPU-bound tasks due to the GIL\n",
    "- Not interruptible/killable -> be careful with memory leaks\n",
    "- increased potential for race conditions\n",
    "\n",
    "## GIL - Global interpreter lock\n",
    "- Lock that allows only one thread to hold control of the Python interpreter. \n",
    "- It allows only one thread to execute at a time even in a multi-threaded architecture.\n",
    "\n",
    "### Why is it needed?\n",
    "It is needed because CPython's (reference implementation of Python) memory management is not thread-safe. \n",
    "Python uses reference counting for memory management.\n",
    "\n",
    "It means that objects created in Python have a reference count variable that keeps track of the number of references that point to the object. \n",
    "When this count reaches zero, the memory occupied by the object is released. \n",
    "The problem was that this reference count variable needed protection from race conditions where two threads increase or decrease its value simultaneously. \n",
    "\n",
    "If this happens, it can cause either leaked memory that is never released or incorrectly release the memory while a reference to that object still exists.\n",
    "\n",
    "### How to avoid the GIL\n",
    "The GIL is very controversial in the Python community. \n",
    "The main way to avoid the GIL is by using multiprocessing instead of threading. \n",
    "Another (however uncomfortable) solution would be to avoid the CPython implementation and use a free-threaded Python implementation like Jython or IronPython. \n",
    "A third option is to move parts of the application out into binary extensions modules, i.e. use Python as a wrapper for third party libraries (e.g. in C/C++). This is the path taken by numypy and scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89a7edf1-1d21-4fa8-8b13-a7252fb248cd",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End main process\n",
      "End main thread\n"
     ]
    }
   ],
   "source": [
    "# Multiprocessing\n",
    "from multiprocessing import Process\n",
    "import os \n",
    "import time\n",
    "\n",
    "def sqaure():\n",
    "    for i in range(100):\n",
    "        i*i\n",
    "        time.sleep(0.01)\n",
    "\n",
    "processes=[]\n",
    "num_process = os.cpu_count()\n",
    "\n",
    "for i in range(num_process):\n",
    "    p = Process(target=sqaure)\n",
    "    processes.append(p)\n",
    "\n",
    "for p in processes:\n",
    "    p.start()\n",
    "\n",
    "# join is used to block main thread until all processes are finished \n",
    "for p in processes:\n",
    "    p.join()\n",
    "    \n",
    "print('End main process')\n",
    "\n",
    "# -----------------------\n",
    "\n",
    "# Multithreading\n",
    "from threading import Thread\n",
    "        \n",
    "threads=[]\n",
    "num_threads = 11\n",
    "\n",
    "for i in range(num_threads):\n",
    "    t = Thread(target=sqaure)\n",
    "    threads.append(t)\n",
    "\n",
    "for t in threads:\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "    \n",
    "print('End main thread')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2198b176-ddb3-4c7c-9225-cf00c2debfaf",
   "metadata": {},
   "source": [
    "## 5. Multithreading\n",
    "\n",
    "- Locks are used to avoid race condition \n",
    "- A lock is like a token that only one thread can hold at a time. \n",
    "- Other threads must wait until the lock is released.\n",
    "- A race condition occurs when two or more threads can access shared data and they try to change it at the same time.\n",
    "- Because the thread scheduling algorithm can swap between threads at any time, you don't know the order in which the threads will attempt to access the shared data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a604acbf-47cf-4218-b73f-28765580bf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start db_val:  0\n",
      "End db_val:  1\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "db_val=0\n",
    "\n",
    "def increase():\n",
    "    global db_val\n",
    "    local_val=db_val\n",
    "    local_val+=1\n",
    "    time.sleep(0.01)\n",
    "    db_val=local_val\n",
    "    # time.sleep(0.01)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    print('Start db_val: ', db_val)\n",
    "    \n",
    "    t1 = Thread(target=increase)\n",
    "    t2 = Thread(target=increase)\n",
    "\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "    \n",
    "    print('End db_val: ', db_val) \n",
    "    # due to race condition caused by t1's sleep time execution of thread\n",
    "    # shifts to t2 being executed in meantime and both threads end up copying 1 into db_val\n",
    "    # this can be avoided by using locks\n",
    "    # so we get 1 instead of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e11b0f7e-a696-48c5-bcb9-56217aa8f031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start db_val:  0\n",
      "End db_val:  2\n"
     ]
    }
   ],
   "source": [
    "# Locks are used to avoid race condition \n",
    "# A lock is like a token that only one thread can hold at a time. \n",
    "# If a thread wants to access shared resources, it must first acquire the lock. \n",
    "# Other threads must wait until the lock is released.\n",
    "# If the state is locked, it does not allow other concurrent threads to enter this code section until the state is unlocked again.\n",
    "\n",
    "from threading import Thread, Lock\n",
    "import time\n",
    "\n",
    "db_val=0\n",
    "\n",
    "def increase(lock):\n",
    "    global db_val\n",
    "\n",
    "    lock.acquire()\n",
    "    local_val=db_val\n",
    "\n",
    "    # processing\n",
    "    local_val+=1\n",
    "    time.sleep(0.01)\n",
    "    db_val=local_val\n",
    "    \n",
    "    lock.release()\n",
    "\n",
    "\n",
    "# using lock with context manager \n",
    "def increase2(lock):\n",
    "    global db_val\n",
    "\n",
    "    with lock:\n",
    "        local_val=db_val\n",
    "        local_val+=1\n",
    "        time.sleep(0.01)\n",
    "        db_val=local_val\n",
    "\n",
    "if __name__=='__main__':\n",
    "    print('Start db_val: ', db_val)\n",
    "    lock = Lock()\n",
    "    t1 = Thread(target=increase2, args=(lock,))\n",
    "    t2 = Thread(target=increase2, args=(lock,))\n",
    "\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "    \n",
    "    print('End db_val: ', db_val) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83da947-a22d-469d-b793-3e3dc2fa18e7",
   "metadata": {},
   "source": [
    "## 5.1 Queues for mt-mp data exchange\n",
    "\n",
    "Queues can be used for thread-safe/process-safe data exchanges and data processing both in a multithreaded and a multiprocessing environment.\n",
    "\n",
    "A queue is a linear data structure that follows the First In First Out (FIFO) principle. A good example is a queue of customers that are waiting in line, where the customer that came first is served first.\n",
    "\n",
    "#### Operations with a queue are thread-safe. Important methods are:\n",
    "\n",
    "- `q.get()` : Remove and return the first item. By default, it blocks until the item is available.\n",
    "- `q.put(item)` : Puts element at the end of the queue. By default, it blocks until a free slot is available.\n",
    "- `q.task_done()` : Indicate that a formerly enqueued task is complete. For each get() you should call this after you are done with your task for this item.\n",
    "- `q.join()` : Blocks until all items in the queue have been gotten and proccessed (task_done() has been called for each item).\n",
    "- `q.empty()` : Return True if the queue is empty.\n",
    "\n",
    "#### Daemon threads\n",
    "- Daemon threads are background threads that automatically die when the main program ends. \n",
    "- This is why the infinite loops inside the worker methods can be exited. Without a daemon process we would have to use a signalling mechanism such as a threading.\n",
    "- Event to stop the worker. But be careful with daemon processes: They are abruptly stopped and their resources (e.g. open files or database transactions) may not be released/completed properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c31bc0-1754-41ea-9a04-b30cd54f6f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in thread_num_1 got 0\n",
      "in thread_num_4 got 1\n",
      "in thread_num_7 got 2\n",
      "in thread_num_9 got 3\n",
      "in thread_num_10 got 4\n",
      "in thread_num_8 got 5\n",
      "in thread_num_2 got 6\n",
      "in thread_num_5 got 7\n",
      "in thread_num_6 got 8\n",
      "in thread_num_3 got 9\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread, Lock, current_thread\n",
    "from queue import Queue\n",
    "\n",
    "def worker(q, lock):\n",
    "    val = q.get() # blocks until the item is available\n",
    "\n",
    "    # do stuff...\n",
    "    with lock: # prevent printing at the same time with this lock\n",
    "        print(f\"in {current_thread().name} got {val}\")\n",
    "        q.task_done()\n",
    "        \n",
    "    # For each get(), a subsequent call to task_done() tells the queue\n",
    "    # that the processing on this item is complete.\n",
    "    # If all tasks are done, q.join() can unblock\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    q = Queue()\n",
    "    lock = Lock()\n",
    "    num_thread = 10\n",
    "\n",
    "    for i in range(num_thread):\n",
    "        t = Thread(name=f\"thread_num_{i+1}\", target=worker, args=(q,lock))\n",
    "        t.daemon = True # dies when the main thread dies\n",
    "        t.start()\n",
    "\n",
    "    # fill the queue with items\n",
    "    for i in range(20):\n",
    "        q.put(i)\n",
    "        \n",
    "    q.join()  # Blocks until all items in the queue have been gotten and processed.\n",
    "    print('main done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c965baa9-d57e-4085-9e79-493e00b24a8b",
   "metadata": {},
   "source": [
    "## 6. Multiprocessing\n",
    "- Call ```process.join()``` to tell the program that it should wait for this process to complete before it continues with the rest of the code.\n",
    "\n",
    "### Share data between processes\n",
    "Since processes don't live in the same memory space, they do not have access to the same (public) data. Thus, they need special shared memory objects to share data.\n",
    "\n",
    "Data can be stored in a shared memory variable using Value or Array.\n",
    "\n",
    "- `Value(type, value)`: Create a ctypes object of type type. Access the value with .target.\n",
    "- `Array(type, value)`: Create a ctypes array with elements of type type. Access the values with [].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4a2915b-1eab-49bc-aaff-7b256e5d4cf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Synchronized' object has no attribute 'Value'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     20\u001b[0m     shared_number_1 \u001b[38;5;241m=\u001b[39m Value(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m) \n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValue at beginning:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mshared_number_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mValue\u001b[49m)\n\u001b[0;32m     23\u001b[0m     shared_array \u001b[38;5;241m=\u001b[39m Array(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m100.0\u001b[39m, \u001b[38;5;241m200.0\u001b[39m])\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArray at beginning:\u001b[39m\u001b[38;5;124m'\u001b[39m, shared_array[:])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Synchronized' object has no attribute 'Value'"
     ]
    }
   ],
   "source": [
    "# Task: Create two processes, each process should have access to a shared variable \n",
    "# and modify it (in this case only increase it repeatedly by 1 for 100 times). \n",
    "# Create another two processes that share an array and modify (increase) all the elements in the array.\n",
    "\n",
    "from multiprocessing import Process, Value, Array\n",
    "import time\n",
    "\n",
    "def add_100(num):\n",
    "    for _ in range(100):\n",
    "        time.sleep(0.01)\n",
    "        num.value += 1\n",
    "    \n",
    "def add_100_to_array(nums):\n",
    "    for _ in range(100):\n",
    "        time.sleep(0.01)\n",
    "        for i in range(len(nums)):\n",
    "            nums[i]+=1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    shared_number_1 = Value('i', 0) \n",
    "    print('Value at beginning:', shared_number_1.value)\n",
    "\n",
    "    shared_array = Array('d', [0.0, 100.0, 200.0])\n",
    "    print('Array at beginning:', shared_array[:])\n",
    "\n",
    "    process1 = Process(target=add_100, args=(shared_number_1,))\n",
    "    process2 = Process(target=add_100, args=(shared_number_1,))\n",
    "\n",
    "    process3 = Process(target=add_100_to_array, args=(shared_array,))\n",
    "    process4 = Process(target=add_100_to_array, args=(shared_array,))\n",
    "\n",
    "    process1.start()\n",
    "    process2.start()\n",
    "    process3.start()\n",
    "    process4.start()\n",
    "\n",
    "    process1.join()\n",
    "    process2.join()\n",
    "    process3.join()\n",
    "    process4.join()\n",
    "\n",
    "    print('Value at end:', shared_number_1.value)\n",
    "    print('Array at end:', shared_array[:])\n",
    "\n",
    "    print('end main')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03099ab1-d4d4-456c-81f1-db9f65406812",
   "metadata": {},
   "source": [
    "## 7. Function Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e11ee27-0f7d-44a3-a554-9ca3e2343926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c337b79a-78f3-4029-a268-982070e2c01f",
   "metadata": {},
   "source": [
    "## 8. Shallow vs Deep Copying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67634b01-c9af-411a-b515-f5bcdbca8db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bd91a10-87ce-473d-be65-b087578273ad",
   "metadata": {},
   "source": [
    "## 9. Asterisk Operator *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e1b649-d576-4d30-9391-463bb83b1cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a45bc51-aaaa-479e-8296-1b0398840ff4",
   "metadata": {},
   "source": [
    "## 10. Context Managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc78f5b7-ab4d-43ab-906d-9df011b7f99a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
